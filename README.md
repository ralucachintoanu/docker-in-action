[![Build](https://github.com/ralucachintoanu/docker-in-action/actions/workflows/build.yml/badge.svg)](https://github.com/ralucachintoanu/docker-in-action/actions/workflows/build.yml)

# Learning Docker: Local Data Pipeline with MongoDB

## ğŸ“Œ Project Overview

This project demonstrates how to build a local data pipeline using **Docker**. The pipeline automates the process of extracting data from a CSV file, transforming it using a Python ETL service, storing it in **MongoDB**, and exposing it via a **Flask API** with **Swagger UI**. **Apache Airflow** is used to schedule the ETL process, and **Mongo Express** provides a web UI to explore the stored data. Everything runs in its own separate Docker container.

## ğŸš€ Technologies Used

- **Docker & Docker Compose** (Containerization & Orchestration)
- **Python** (ETL and API development with Flask, Pandas, and Swagger)
- **Poetry** (Dependency and environment management)
- **MongoDB** (Database for storing processed trip data)
- **Mongo Express** (Web UI for MongoDB)
- **Apache Airflow** (Workflow orchestration for scheduling ETL jobs)
- **Justfile** (Simplified command runner for local dev tasks and CI integration)
- **GitHub Actions** (Continuous integration pipeline for testing, linting, and formatting)

## ğŸ“‚ Project Structure

```
docker-in-action/
â”‚
â”‚-- etl/                   # ETL Service
â”‚   â”œâ”€â”€ etl.py             # Extracts, transforms, and loads data into MongoDB
â”‚   â”œâ”€â”€ Dockerfile         # Dockerfile for ETL service
â”‚   â”œâ”€â”€ dataset_sample.csv # Dataset file
â”‚   â”œâ”€â”€ pyproject.toml     # Poetry config for etl module
â”‚   â”œâ”€â”€ poetry.lock
â”‚
â”‚-- api/                   # Flask API Service
â”‚   â”œâ”€â”€ app.py             # Serves processed data
â”‚   â”œâ”€â”€ Dockerfile         # Dockerfile for Flask API
â”‚   â”œâ”€â”€ pyproject.toml     # Poetry config for api module
â”‚   â”œâ”€â”€ poetry.lock
â”‚
â”‚-- airflow/               # Airflow for ETL Scheduling
â”‚   â”œâ”€â”€ dags/              # Airflow DAGs folder
â”‚
â”‚-- .github/               # GitHub Actions CI workflows
â”‚   â”œâ”€â”€ workflows/         # Folder for GitHub Actions workflows
â”‚   â”‚   â””â”€â”€ build.yml      # CI pipeline for building, linting, and testing
â”‚
â”‚-- docker-compose.yml     # Orchestrates all services
â”‚-- justfile               # Defines a handy way to run multiple commands
â”‚-- README.md              # Project Documentation
```

## ğŸ”§ Setup & Usage

### 1ï¸âƒ£ Create an .env file in the root folder with the following properties:

```sh
MONGO_INITDB_ROOT_USERNAME=...
MONGO_INITDB_ROOT_PASSWORD=...
MONGO_EXPRESS_USERNAME=...
MONGO_EXPRESS_PASSWORD=...
AIRFLOW_USRENAME=...
AIRFLOW_PASSWORD=...
```

### 2ï¸âƒ£ Build the project (check format, run lint, tests, test coverage, ...)

```sh
just build
```

### 3ï¸âƒ£ Start Containers

```sh
just start-all
```

### 4ï¸âƒ£ Access Services

- **Mongo Express UI**: [http://localhost:8081](http://localhost:8081)
- **Flask API**: [http://localhost:5000](http://localhost:5000)
- **Airflow UI**: [http://localhost:8080](http://localhost:8080)

### 5ï¸âƒ£ Stop Services

```sh
just stop-all
```
